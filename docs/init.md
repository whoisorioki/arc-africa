# The ARC Challenge Documentation Standard

To meet Zindi's requirement for "full documentation" and to ensure every part of our code is clear, reproducible, and maintainable, the coding agent must adhere to the following documentation standard for every function, class, and method created in the project.

We will adopt a format based on the Google Python Style Guide for docstrings. This format is clean, human-readable, and easily parsed by automated tools.

## Cursor-Ready Documentation Template

```python
"""A brief, one-line summary of the function's purpose.

A more detailed explanation of the function's logic, its role within the
broader system, and any important assumptions or design choices made.
This section should clearly explain the 'why' behind the code, referencing
any specific papers or techniques if applicable.

Args:
    arg_name (type): A description of the argument. Explain its purpose,
        expected format (e.g., NumPy array, list of objects), and any
        constraints.
    kwarg_name (type, optional): A description of the keyword argument.
        Defaults to `default_value`.

Returns:
    return_type: A description of the value returned by the function.
        Specify the format and what it represents (e.g., a list of
        structured object dictionaries, a transformed NumPy grid).
    (If multiple values are returned, list each on a new line).

Raises:
    ErrorType: A description of any errors that may be raised and under
        what conditions (e.g., if an input grid has invalid dimensions).

Example:
    >>> grid = np.array([[1, 1], ])
    >>> segmented_objects = segment_grid(grid)
    >>> print(segmented_objects)
    [{'color': 1, 'size': 2,...}, {'color': 2, 'size': 1,...}]
"""
```

### Why this template is crucial for success

- **Reproducibility:** By clearly defining inputs, outputs, and behaviors, we make it easy for reviewers (and ourselves) to understand and run the code.
- **Clarity:** The detailed description section fulfills the requirement to explain features and logic. This is where the agent will document the reasoning behind specific algorithms (e.g., "This implements a connected-component search to satisfy FR1...").
- **Efficiency:** A consistent format allows for faster development and debugging, as the purpose and usage of any piece of code are immediately clear.

---

# Best-Practice Project Structure

A well-organized project is essential for managing complexity and ensuring a smooth submission process. The following directory structure is designed specifically for our neuro-symbolic solver, mapping directly to the components outlined in the Product Requirements Document (PRD).

```
arc_challenge_solver/
│
├── data/
│   ├── training/              # ARC-AGI official 400 training tasks
│   ├── evaluation/            # ARC-AGI official 400 evaluation tasks
│   └── synthetic/             # Large-scale dataset generated by our pipeline
│
├── notebooks/
│   ├── 01_eda.ipynb           # Initial exploratory data analysis and visualization
│   ├── 02_dsl_prototyping.ipynb # Notebook for testing DSL primitives
│   └── 03_model_testing.ipynb # Experiments with the neural guide
│
├── src/
│   ├── __init__.py
│   ├── data_pipeline/         # Corresponds to PRD Phase 1: Foundational Toolkit
│   │   ├── __init__.py
│   │   ├── segmentation.py    # FR1: Object segmentation and representation
│   │   └── augmentation.py    # FR3: Data augmentation and synthetic generation
│   │
│   ├── dsl/                   # Corresponds to PRD Phase 1: Foundational Toolkit
│   │   ├── __init__.py
│   │   └── primitives.py      # FR2: Implementation of core DSL functions
│   │
│   ├── symbolic_search/       # Corresponds to PRD Phase 2: Core Components
│   │   ├── __init__.py
│   │   ├── search.py          # FR4: Search algorithm (e.g., beam search)
│   │   └── verifier.py        # FR4: Module to verify programs against examples
│   │
│   ├── neural_guide/          # Corresponds to PRD Phase 2: Core Components
│   │   ├── __init__.py
│   │   ├── architecture.py    # FR5: Transformer model definition (PyTorch)
│   │   └── train.py           # FR5: Script for pre-training the neural guide
│   │
│   └── solver/                # Corresponds to PRD Phase 3: Integration
│       ├── __init__.py
│       └── main_solver.py     # FR6 & FR7: Integrated neuro-symbolic solver and TTT loop
│
├── models/
│   └── neural_guide_pretrained.pth # Stores the weights of the pre-trained model
│
├── scripts/
│   ├── run_training.sh        # Script to execute the full training pipeline
│   └── generate_submission.py # Main script to run the solver on test data and create submission.csv
│
├── tests/
│   ├── test_segmentation.py   # Unit tests for the object segmentation module
│   └── test_dsl_primitives.py # Unit tests for the DSL functions
│
├── README.md                  # High-level project overview, setup, and usage instructions
└── requirements.txt           # All Python packages and versions used, critical for reproducibility
```

### Rationale for this structure

- **Separation of Concerns:** Each core component from our PRD has its own dedicated module (`data_pipeline`, `dsl`, `symbolic_search`, `neural_guide`), making the system modular and easy to navigate.
- **Data Integrity:** A clear separation between raw `data`, exploratory `notebooks`, and operational `src` code prevents accidental modification of original datasets and ensures a clean workflow.
- **Submission-Ready:** This structure is designed with the final code review in mind. The `README.md` will serve as the main entry point for reviewers, and the `requirements.txt` file ensures the environment can be perfectly replicated, a key requirement for a successful review.

By instructing your coding agent to adhere strictly to these documentation and structural guidelines, we will build a professional, robust, and highly competitive solution. 